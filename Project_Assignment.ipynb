{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bRdJ0_o2BCpK",
        "MCt9pJZvEkfw",
        "IzpteW1JEr4B",
        "UF4vaIhvMqHu",
        "rQgtH-faBiGW"
      ],
      "authorship_tag": "ABX9TyMzbbM4Bg1FS2cZwii2ihtO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXwF52iXMccG",
        "colab_type": "text"
      },
      "source": [
        "# Project Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D93JAy_dVSg",
        "colab_type": "text"
      },
      "source": [
        " ## Importing Dependencies(Libraries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAK8-A7tHBdo",
        "colab_type": "text"
      },
      "source": [
        "Major Libraries Used : TensorFlow, Keras, scikit-learn, matplotlib, NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzT8J9WydjQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRdJ0_o2BCpK",
        "colab_type": "text"
      },
      "source": [
        "## Loading and Splitting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BqVrmOwGNBd",
        "colab_type": "text"
      },
      "source": [
        "We will be using 2 different dataset for the completion of the assignments\n",
        "1. CIFAR10\n",
        "2. Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCt9pJZvEkfw",
        "colab_type": "text"
      },
      "source": [
        "### Loading and Splitting CIFAR10 DATA into Train, Validation and Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqK5A4psBHL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the data into Train and Test. The Test Data should be completely unseen.\n",
        "(cifar_train_x_temp, cifar_train_y_temp), (cifar_test_x , cifar_test_y) =tf.keras.datasets.cifar10.load_data() \n",
        "#By default 10000 instances are used as test data in Cifar10\n",
        "\n",
        "cifar_train_x, cifar_val_x, cifar_train_y, cifar_val_y = train_test_split(cifar_train_x_temp, cifar_train_y_temp, test_size=0.20, random_state=42)\n",
        "#Further, for hyperparameter tuning, 20% of the train data is futher split into train and validation data"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89fRmsecCqYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0301db3e-7c70-41ca-f31d-ffa2b48d10ba"
      },
      "source": [
        "print('cifar10 train data      : {}'.format(cifar_train_x.shape))\n",
        "print('cifar10 validation data : {}'.format(cifar_val_x.shape))\n",
        "print('cifar10 test data       : {}'.format(cifar_test_x.shape))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar10 train data      : (40000, 32, 32, 3)\n",
            "cifar10 validation data : (10000, 32, 32, 3)\n",
            "cifar10 test data       : (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nncS5aMfJCpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b4f9bb60-6aa4-44dd-d8da-3331f12877cf"
      },
      "source": [
        "cifar_train_x = cifar_train_x/255\n",
        "cifar_train_x = cifar_train_x.shuffle(buffer_size = 40000).batch(500).repeat()\n",
        "cifar_val_x  = cifar_val_x/255\n",
        "cifar_test_x = cifar_test_x/255\n",
        "\n",
        "#Standardizing the train dataset\n",
        "#cifar_train_y = cifar_train_y.reshape((-1))\n",
        "#cifar_train_data = tf.data.Dataset.from_tensor_slices((cifar_train_x.reshape([-1,32,32,3]).astype(np.float32)/255, cifar_train_y.astype(np.int32)))\n",
        "#cifar_train_data = cifar_train_data.shuffle(buffer_size = 40000).batch(500).repeat()\n",
        "\n",
        "\n",
        "#Standardizing the validation dataset\n",
        "#cifar_val_y = cifar_val_y.reshape((-1))\n",
        "#cifar_val_data = tf.data.Dataset.from_tensor_slices((cifar_val_x.reshape([-1,32,32,3]).astype(np.float32)/255, cifar_val_y.astype(np.int32)))\n",
        "#cifar_val_data = cifar_val_data.shuffle(buffer_size = 10000).batch(200)\n",
        "\n",
        "#Standardizing the test dataset\n",
        "#cifar_test_y = cifar_test_y.reshape((-1))\n",
        "#cifar_test_data = tf.data.Dataset.from_tensor_slices((cifar_test_x.reshape([-1,32,32,3]).astype(np.float32)/255, cifar_test_y.astype(np.int32)))\n",
        "#cifar_test_data = cifar_test_data.shuffle(buffer_size = 10000).batch(200)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-01d53c1de485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcifar_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar_train_x\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcifar_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcifar_val_x\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcifar_val_x\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcifar_test_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar_test_x\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'shuffle'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzpteW1JEr4B",
        "colab_type": "text"
      },
      "source": [
        "### Loading and Splitting MNIST FASHION DATA into Train, Validation and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN5-zJyOE4K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(mnist_train_x_temp, mnist_train_y_temp), (mnist_test_x , mnist_test_y) =fashion_mnist.load_data() \n",
        "#Splitting the data into Train and Test. The Test Data should be completely unseen.\n",
        "#By default 10000 instances are used as test data in Fashion Mnist\n",
        "mnist_train_x, mnist_val_x, mnist_train_y, mnist_val_y = train_test_split(mnist_train_x_temp, mnist_train_y_temp, test_size=0.20, random_state=42)\n",
        "#Further, for hyperparameter tuning, 20% of the train data is futher split into train and validation data"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfJAceOuFr4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "656cc710-4470-41bd-fa87-4a16691830c3"
      },
      "source": [
        "print('MNIST FASHION train data      : {}'.format(mnist_train_x.shape))\n",
        "print('MNIST FASHION validation data : {}'.format(mnist_val_x.shape))\n",
        "print('MNIST FASHION test data       : {}'.format(mnist_test_x.shape))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST FASHION train data      : (48000, 28, 28)\n",
            "MNIST FASHION validation data : (12000, 28, 28)\n",
            "MNIST FASHION test data       : (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5rO7CHPJPUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardizing the train dataset\n",
        "#mnist_train_y = mnist_train_y.reshape((-1))\n",
        "#cifar_train_x = tf.data.Dataset.from_tensor_slices((mnist_train_x.reshape([-1,32,32,3]).astype(np.float32)/255, mnist_train_y.astype(np.int32)))\n",
        "\n",
        "#Standardizing the validation dataset\n",
        "#mnist_val_y = mnist_val_y.reshape((-1))\n",
        "#mnist_val_x = tf.data.Dataset.from_tensor_slices((mnist_val_x.reshape([-1,32,32,3]).astype(np.float32)/255, mnist_val_y.astype(np.int32)))\n",
        "\n",
        "#Standardizing the test dataset\n",
        "#mnist_test_y = mnist_test_y.reshape((-1))\n",
        "#mnist_test_x = tf.data.Dataset.from_tensor_slices((mnist_test_x.reshape([-1,32,32,3]).astype(np.float32)/255, mnist_test_y.astype(np.int32)))\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF4vaIhvMqHu",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRE5dr6hZEjG",
        "colab_type": "text"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozBleTfLMyVU",
        "colab_type": "text"
      },
      "source": [
        "* Motivation    : Analyze the affect of different Optimizers on the training behaviour\n",
        "  \n",
        " * Optimizer 1: Adadelta,\n",
        " * Optimizer 2: Adagrad\n",
        " * Optimizer 3: Adam)\n",
        " * Optimizer 4: Adamax,\n",
        " * Optimizer 5: Ftrl,\n",
        " * Optimizer 6: Nadam,\n",
        " * Optimizer 7: SGD\n",
        "\n",
        "* Dataset       :\n",
        " * Cifar10, \n",
        " *MNIST Fashion\n",
        "\n",
        "* Architecture  :\n",
        " * Basic Convolutional Neural Network\n",
        " * Resnet\n",
        " * InceptionNet\n",
        " * Densely Connected Convolutional Neural Network\n",
        "\n",
        "* Comparision Criteria : Training Curve\n",
        " * Steps unitll convergence\n",
        " * Training Accuracy \n",
        " * Loss\n",
        " * Stability of Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8S35KUbKKcG",
        "colab_type": "text"
      },
      "source": [
        "### TASK 1.1 BASIC Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRhhL7rUGbpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def basic_cnn(ker_size, pad, act,opt,train_x,train_y ,epochs,val_x,val_y):\n",
        "  cnn_model = models.Sequential()\n",
        "  cnn_model.add(layers.Conv2D(16,kernel_size=ker_size, padding=pad, activation=act, input_shape=(32,32,3)))\n",
        "  cnn_model.add(layers.MaxPool2D((2,2)))\n",
        "  cnn_model.add(layers.Conv2D(32,kernel_size=ker_size, padding=pad, activation=act))\n",
        "  cnn_model.add(layers.MaxPool2D((2,2)))\n",
        "  cnn_model.add(layers.Conv2D(64,kernel_size=ker_size, padding=pad, activation=act))\n",
        "  cnn_model.add(layers.MaxPool2D((2,2)))\n",
        "  cnn_model.add(layers.Conv2D(128,kernel_size=ker_size, padding=pad, activation=act))\n",
        "  cnn_model.add(layers.MaxPool2D((2,2)))\n",
        "  cnn_model.add(layers.Conv2D(256,kernel_size=ker_size, padding=pad, activation=act))\n",
        "  cnn_model.add(layers.MaxPool2D((2,2)))\n",
        "  cnn_model.add(layers.Flatten())\n",
        "  cnn_model.add(layers.Dense(128,activation=act))\n",
        "  cnn_model.add(layers.Dense(10))\n",
        "\n",
        "  cnn_model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "  history = cnn_model.fit(train_x, train_y,epochs,validation_data=(val_x, val_y))\n",
        "  return (cnn_model, history)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQZn6oqHP2jD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "47f64162-d9a7-4435-c60e-dedb4b0957c8"
      },
      "source": [
        "cnn_model,history = basic_cnn(3,'SAME','relu','adam',cifar_train_x,cifar_train_y,10000,cifar_val_x,cifar_val_y)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/4 [==============>...............] - ETA: 0s - loss: 19.6529 - accuracy: 0.1037WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0146s vs `on_train_batch_end` time: 0.1835s). Check your callbacks.\n",
            "4/4 [==============================] - 1s 218ms/step - loss: 22.4150 - accuracy: 0.1007 - val_loss: 2.3025 - val_accuracy: 0.1017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQgtH-faBiGW",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 : Reqularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk7jZNgOZo96",
        "colab_type": "text"
      },
      "source": [
        "* Motivation: Investigate how different Regularization techniques affect the training behavior.\n",
        "\n",
        "* Dataset : Cifar10\n",
        "\n",
        "* Architecture : Best model from Task1's architecture\n",
        "\n",
        "* Regularization techniques:\n",
        " * L1, L2 regularizer\n",
        " * Dropouts\n",
        " * Adding noise\n",
        "\n",
        "* Comparision Criteria: Training Curves\n",
        " * Steps still convergence\n",
        " * Training accuracy untill convergence\n",
        " * Stability of training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCk4ei_phKg2",
        "colab_type": "text"
      },
      "source": [
        "## Task 3: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr94NiqF6-E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}